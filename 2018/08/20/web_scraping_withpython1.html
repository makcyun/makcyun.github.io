<!-- build time:Sun Jun 09 2019 21:32:14 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html class="theme-next pisces use-motion" lang="zh-Hans"><head><meta name="google-site-verification" content="s0oCkquJSvsBetEUl3d8nDj5jYzNitxDJALA37MiIyM"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-flash.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="requests,正则表达式,beautifulsoup,css,xpath,lxml,Python爬虫,"><link rel="alternate" href="/atom.xml" title="高级农民工" type="application/atom+xml"><meta name="description" content="python爬虫第1篇利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。"><meta name="keywords" content="requests,正则表达式,beautifulsoup,css,xpath,lxml,Python爬虫"><meta property="og:type" content="article"><meta property="og:title" content="Python爬虫(1):多种方法爬取猫眼top100电影"><meta property="og:url" content="https://www.makcyun.top/2018/08/20/web_scraping_withpython1.html"><meta property="og:site_name" content="高级农民工"><meta property="og:description" content="python爬虫第1篇利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="http://media.makcyun.top/18-8-19/49818413.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/28479553.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-20/66062822.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/18415362.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/84055565.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/840042.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/87341266.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-20/66910595.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/28479553.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-19/34117279.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-20/80083042.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-21/57684234.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-20/32342735.jpg"><meta property="og:image" content="http://media.makcyun.top/18-8-20/66062822.jpg"><meta property="og:updated_time" content="2018-12-19T03:12:32.957Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Python爬虫(1):多种方法爬取猫眼top100电影"><meta name="twitter:description" content="python爬虫第1篇利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。"><meta name="twitter:image" content="http://media.makcyun.top/18-8-19/49818413.jpg"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Pisces",version:"5.1.4",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!0,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="https://www.makcyun.top/2018/08/20/web_scraping_withpython1.html"><title>Python爬虫(1):多种方法爬取猫眼top100电影 | 高级农民工</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><meta name="baidu-site-verification" content="E65frtf6P6"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">高级农民工</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">Beginner's Mind</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首&emsp;&emsp;页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于博主</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归&emsp;&emsp;档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标&emsp;&emsp;签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分&emsp;&emsp;类</a></li><li class="menu-item menu-item-top"><a href="/top/" rel="section"><i class="menu-item-icon fa fa-fw fa-signal"></i><br>最受欢迎</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>站内搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://www.makcyun.top/2018/08/20/web_scraping_withpython1.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="高级农民工"><meta itemprop="description" content=""><meta itemprop="image" content="http://media.makcyun.top/201901230951_146.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="高级农民工"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Python爬虫(1):多种方法爬取猫眼top100电影</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-20T19:18:14+08:00">2018-08-20 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Python爬虫/" itemprop="url" rel="index"><span itemprop="name">Python爬虫</span> </a></span></span><span id="/2018/08/20/web_scraping_withpython1.html" class="leancloud_visitors" data-flag-title="Python爬虫(1):多种方法爬取猫眼top100电影"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">热度&#58;</span> <span class="leancloud-visitors-count"></span> <span>℃</span></span><div class="post-wordcount"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">9,078 字 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">41 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p><b><em>python爬虫第1篇</em></b><br>利用Request请求库和4种内容提取方法：正则表达式、lxml+xpath、Beatutifulsoup+css选择器、Beatutifulsoup+find_all爬取网页内容。</p><a id="more"></a><p><strong>摘要：</strong> 作为小白，<strong>爬虫可以说是入门python最快和最容易获得成就感的途径</strong>。因为初级爬虫的套路相对固定，常见的方法只有几种，比较好上手。最近，跟着崔庆才大佬的书：<em>python3网络爬虫开发实战</em> 学习爬虫。选取网页结构较为简单的猫眼top100电影为案例进行练习。 <strong>重点是用上述所说的4种方法提取出关键内容</strong>。一个问题采用不同的解决方法有助于拓展思维，通过不断练习就能够灵活运用。</p><blockquote><p><strong>本文知识点：</strong><br>Requsts 请求库的使用<br>beautiful+lxml两大解析库使用<br>正则表达式 、xpath、css选择器的使用</p></blockquote><p><img src="http://media.makcyun.top/18-8-19/49818413.jpg" alt=""></p><h2 id="1-为什么爬取该网页？"><a href="#1-为什么爬取该网页？" class="headerlink" title="1. 为什么爬取该网页？"></a>1. 为什么爬取该网页？</h2><ul><li>比较懒，不想一页页地去翻100部电影的介绍，<strong>想在一个页面内进行总体浏览</strong>（比如在excel表格中）；</li></ul><p><img src="http://media.makcyun.top/18-8-19/28479553.jpg" alt=""></p><ul><li>想<strong>深入了解一些比较有意思的信息</strong>，比如：哪部电影的评分最高？哪位演员的作品数量最多？哪个国家/地区上榜的电影数量最多？哪一年上榜的电影作品最多等。这些信息在网页上是不那么容易能直接获得的，所以需要爬虫。</li></ul><p><img src="http://media.makcyun.top/18-8-20/66062822.jpg" alt=""></p><h2 id="2-爬虫目标"><a href="#2-爬虫目标" class="headerlink" title="2. 爬虫目标"></a>2. 爬虫目标</h2><ul><li>从网页中提取出top100电影的电影名称、封面图片、排名、评分、演员、上映国家/地区、评分等信息，并保存为csv文本文件。</li><li>根据爬取结果，进行简单的可视化分析。</li></ul><p>平台：windows7 + SublimeText3</p><h2 id="3-爬取步骤"><a href="#3-爬取步骤" class="headerlink" title="3. 爬取步骤"></a>3. 爬取步骤</h2><h3 id="3-1-网址URL分析"><a href="#3-1-网址URL分析" class="headerlink" title="3.1. 网址URL分析"></a>3.1. 网址URL分析</h3><p>首先，打开猫眼Top100的url网址： <a href="http://maoyan.com/board/4?offset=0" target="_blank" rel="noopener"><strong>http://maoyan.com/board/4?offset=0</strong></a>。页面非常简单，所包含的信息就是上述所说的爬虫目标。下拉页面到底部，点击第2页可以看到网址变为：<strong><a href="http://maoyan.com/board/4?offset=10" target="_blank" rel="noopener">http://maoyan.com/board/4?offset=10</a></strong>。因此，可以推断出url的变化规律：offset表示偏移，10代表一个页面的电影偏移数量，即：第一页电影是从0-10，第二页电影是从11-20。因此，获取全部100部电影，只需要构造出10个url，然后依次获取网页内容，再用不同的方法提取出所需内容就可以了。<br>下面，用requests方法获取第一个页面。</p><h3 id="3-2-Requests获取首页数据"><a href="#3-2-Requests获取首页数据" class="headerlink" title="3.2. Requests获取首页数据"></a>3.2. Requests获取首页数据</h3><p>先定义一个获取单个页面的函数：get_one_page()，传入url参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>&#125;</span><br><span class="line">        <span class="comment"># 不加headers爬不了</span></span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="comment"># try-except语句捕获异常</span></span><br></pre></td></tr></table></figure><p>接下来在main()函数中设置url。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    print(html)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>运行上述程序后，首页的源代码就被爬取下来了。如下图所示：</p><p><img src="http://media.makcyun.top/18-8-19/18415362.jpg" alt=""></p><p>接下来就需要从整个网页中提取出几项我们需要的内容，用到的方法就是上述所说的四种方法，下面分别进行说明。</p><h3 id="3-3-4种内容解析提取方法"><a href="#3-3-4种内容解析提取方法" class="headerlink" title="3.3. 4种内容解析提取方法"></a>3.3. 4种内容解析提取方法</h3><h4 id="3-3-1-正则表达式提取"><a href="#3-3-1-正则表达式提取" class="headerlink" title="3.3.1. 正则表达式提取"></a>3.3.1. 正则表达式提取</h4><p>第一种是利用<strong>正则表达式</strong>提取。<br>什么是正则表达式？ 下面这串看起来乱七八糟的符号就是正则表达式的语法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name&quot;&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?&apos;</span><br></pre></td></tr></table></figure><p>它是一种强大的字符串处理工具。之所以叫正则表达式，是因为它们可以识别正则字符串（regular string）。可以这么定义：“ 如果你给我的字符串符合规则，我就返回它”；“如果字符串不符合规则，我就忽略它”。通过requests抓取下来的网页是一堆大量的字符串，用它处理后便可提取出我们想要的内容。</p><p>如果还不了解它，可以参考下面的教程：</p><blockquote><p><a href="http://www.runoob.com/regexp/regexp-syntax.html" target="_blank" rel="noopener">http://www.runoob.com/regexp/regexp-syntax.html</a><br><a href="https://www.w3cschool.cn/regexp/zoxa1pq7.html" target="_blank" rel="noopener">https://www.w3cschool.cn/regexp/zoxa1pq7.html</a></p></blockquote><p><strong>正则表达式常用语法：</strong></p><style>table th:nth-of-type(1){width:60px}</style><table><thead><tr><th style="text-align:center">模式</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">\w</td><td style="text-align:center">匹配字母数字及下划线</td></tr><tr><td style="text-align:center">\W</td><td style="text-align:center">匹配非字母数字及下划线</td></tr><tr><td style="text-align:center">\s</td><td style="text-align:center">匹配任意空白字符，等价于 [\t\n\r\f]</td></tr><tr><td style="text-align:center">\S</td><td style="text-align:center">匹配任意非空字符</td></tr><tr><td style="text-align:center">\d</td><td style="text-align:center">匹配任意数字，等价于 [0-9]</td></tr><tr><td style="text-align:center">\D</td><td style="text-align:center">匹配任意非数字</td></tr><tr><td style="text-align:center">\n</td><td style="text-align:center">匹配一个换行符</td></tr><tr><td style="text-align:center">\t</td><td style="text-align:center">匹配一个制表符</td></tr><tr><td style="text-align:center">^</td><td style="text-align:center">匹配字符串开始位置的字符</td></tr><tr><td style="text-align:center">$</td><td style="text-align:center">匹配字符串的末尾</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">匹配任意字符，除了换行符</td></tr><tr><td style="text-align:center">[…]</td><td style="text-align:center">用来表示一组字符，单独列出：[amk] 匹配 ‘a’，’m’ 或 ‘k’</td></tr><tr><td style="text-align:center">[^…]</td><td style="text-align:center">不在 [ ] 中的字符</td></tr><tr><td style="text-align:center">*</td><td style="text-align:center">匹配前面的字符、子表达式或括号里的字符 0 次或多次</td></tr><tr><td style="text-align:center">+</td><td style="text-align:center">同上，匹配至少一次</td></tr><tr><td style="text-align:center">?</td><td style="text-align:center">同上，匹配0到1次</td></tr><tr><td style="text-align:center">{n}</td><td style="text-align:center">匹配前面的字符、子表达式或括号里的字符 n 次</td></tr><tr><td style="text-align:center">{n, m}</td><td style="text-align:center">同上，匹配 m 到n 次（包含 m 或 n）</td></tr><tr><td style="text-align:center">( )</td><td style="text-align:center">匹配括号内的表达式，也表示一个组</td></tr></tbody></table><p>下面，开始提取关键内容。右键网页-检查-Network选项，选中左边第一个文件然后定位到电影信息的相应位置，如下图：</p><p><img src="http://media.makcyun.top/18-8-19/84055565.jpg" alt=""></p><p>可以看到每部电影的相关信息都在<strong>dd</strong>这个节点之中。所以就可以从该节点运用正则进行提取。<br>第1个要提取的内容是电影的排名。它位于class=”board-index”的<strong>i</strong>节点内。不需要提取的内容用’.*?’替代，需要提取的数字排名用（）括起来，（）里面的数字表示为（\d+）。正则表达式可以写为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;&apos;</span><br></pre></td></tr></table></figure><p>接着，第2个需要提取的是封面图片，图片网址位于img节点的’data-src’属性中，正则表达式可写为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;data-src=&quot;(.*?)&quot;.*?&apos;</span><br></pre></td></tr></table></figure><p>第1和第2个正则之间的代码是不需要的，用’.*?’替代，所以这两部分合起来写就是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;</span><br></pre></td></tr></table></figure><p>同理，可以依次用正则写下主演、上映时间和评分等内容,完整的正则表达式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&apos;&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name&quot;&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star&quot;&gt;(.*?)&lt;/p&gt;.*?releasetime&quot;&gt;(.*?)&lt;/p.*?integer&quot;&gt;(.*?)&lt;/i&gt;.*?fraction&quot;&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;&apos;</span><br></pre></td></tr></table></figure><p>正则表达式写好以后，可以定义一个页面解析提取方法：parse_one_page（），用来提取内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page</span><span class="params">(html)</span>:</span></span><br><span class="line">    pattern = re.compile(</span><br><span class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</span><br><span class="line">    <span class="comment"># re.S表示匹配任意字符，如果不加，则无法匹配换行符</span></span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="comment"># print(items)</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'index'</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(item[<span class="number">1</span>]),  <span class="comment"># 定义get_thumb()方法进一步处理网址</span></span><br><span class="line">            <span class="string">'name'</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">'star'</span>: item[<span class="number">3</span>].strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="comment"># 'time': item[4].strip()[5:],</span></span><br><span class="line">            <span class="comment"># 用两个方法分别提取time里的日期和地区</span></span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: item[<span class="number">5</span>].strip() + item[<span class="number">6</span>].strip()</span><br><span class="line">            <span class="comment"># 评分score由整数+小数两部分组成</span></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>re.S:</strong>匹配任意字符，如果不加，则无法匹配换行符；<br><strong>yield:</strong>使用yield的好处是作为生成器，可以遍历迭代，并且将数据整理形成字典，输出结果美观。具体用法可参考：<a href="https://blog.csdn.net/zhangpinghao/article/details/18716275；" target="_blank" rel="noopener">https://blog.csdn.net/zhangpinghao/article/details/18716275；</a><br><strong>.strip():</strong>用于去掉字符串中的空格。</p></blockquote><p>上面程序为了便于提取内容，又定义了3个方法：get_thumb（）、get_release_time（）和 get_release_area（）：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取封面大图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_thumb</span><span class="params">(url)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)@.*?'</span>)</span><br><span class="line">    thumb = re.search(pattern, url)</span><br><span class="line">    <span class="keyword">return</span> thumb.group(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># http://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c</span></span><br><span class="line"><span class="comment"># 去掉@160w_220h_1e_1c就是大图    </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取上映时间函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_time</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)(\(|$)'</span>)</span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)  <span class="comment"># 返回匹配到的第一个括号(.*?)中结果即时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取国家/地区函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_area</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'.*\((.*)\)'</span>)</span><br><span class="line">    <span class="comment"># $表示匹配一行字符串的结尾，这里就是(.*?)；\(|$,表示匹配字符串含有(,或者只有(.*?)</span></span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>‘r’：</strong>正则前面加上’r’ 是为了告诉编译器这个string是个raw string，不要转意’\’。当一个字符串使用了正则表达式后，最好在前面加上’r’；<br><strong>‘|’ ‘$’：</strong> 正则’|’表示或’，’$’表示匹配一行字符串的结尾；<br><strong>.group(1)</strong>：意思是返回search匹配的第一个括号中的结果，即(.*?)，gropup()则返回所有结果2013-12-18(，group(1)返回’（’。</p></blockquote><p>接下来，修改main()函数来输出爬取的内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        print(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>if <strong>name</strong> == ‘_ _main__’:</strong>当.py文件被直接运行时，if <strong>name</strong> == ‘_ <em>main__’之下的代码块将被运行；当.py文件以模块形式被导入时，if <strong>name</strong> == ‘</em> _main__’之下的代码块不被运行。<br>参考：<a href="https://blog.csdn.net/yjk13703623757/article/details/77918633。" target="_blank" rel="noopener">https://blog.csdn.net/yjk13703623757/article/details/77918633。</a></p></blockquote><p>运行程序，就可成功地提取出所需内容，结果如下：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'1'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg'</span>, <span class="string">'name'</span>: <span class="string">'霸王别姬'</span>, <span class="string">'star'</span>: <span class="string">'张国荣,张丰毅,巩俐'</span>, <span class="string">'time'</span>: <span class="string">'1993-01-01'</span>, <span class="string">'area'</span>: <span class="string">'中国香港'</span>, <span class="string">'score'</span>: <span class="string">'9.6'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'2'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/54617769d96807e4d81804284ffe2a27239007.jpg'</span>, <span class="string">'name'</span>: <span class="string">'罗马假日'</span>, <span class="string">'star'</span>: <span class="string">'格利高里·派克,奥黛丽·赫本,埃迪·艾伯特'</span>, <span class="string">'time'</span>: <span class="string">'1953-09-02'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.1'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'3'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/283292171619cdfd5b240c8fd093f1eb255670.jpg'</span>, <span class="string">'name'</span>: <span class="string">'肖申克的救赎'</span>, <span class="string">'star'</span>: <span class="string">'蒂姆·罗宾斯,摩根·弗里曼,鲍勃·冈顿'</span>, <span class="string">'time'</span>: <span class="string">'1994-10-14'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.5'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'4'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p0.meituan.net/movie/e55ec5d18ccc83ba7db68caae54f165f95924.jpg'</span>, <span class="string">'name'</span>: <span class="string">'这个杀手不太冷'</span>, <span class="string">'star'</span>: <span class="string">'让·雷诺,加里·奥德曼,娜塔莉·波特曼'</span>, <span class="string">'time'</span>: <span class="string">'1994-09-14'</span>, <span class="string">'area'</span>: <span class="string">'法国'</span>, <span class="string">'score'</span>: <span class="string">'9.5'</span>&#125;</span><br><span class="line">&#123;<span class="string">'index'</span>: <span class="string">'5'</span>, <span class="string">'thumb'</span>: <span class="string">'http://p1.meituan.net/movie/f5a924f362f050881f2b8f82e852747c118515.jpg'</span>, <span class="string">'name'</span>: <span class="string">'教父'</span>, <span class="string">'star'</span>: <span class="string">'马龙·白兰度,阿尔·帕西诺,詹姆斯·肯恩'</span>, <span class="string">'time'</span>: <span class="string">'1972-03-24'</span>, <span class="string">'area'</span>: <span class="string">'美国'</span>, <span class="string">'score'</span>: <span class="string">'9.3'</span>&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">[Finished <span class="keyword">in</span> <span class="number">1.9</span>s]</span><br></pre></td></tr></table></figure><p>以上是第1种提取方法，如果还不习惯正则表达式这种复杂的语法，可以试试下面的第2种方法。</p><h4 id="3-3-2-lxml结合xpath提取"><a href="#3-3-2-lxml结合xpath提取" class="headerlink" title="3.3.2. lxml结合xpath提取"></a>3.3.2. lxml结合xpath提取</h4><p>该方法需要用到<strong>lxml</strong>这款解析利器，同时搭配xpath语法，利用它的的路径选择表达式，来高效提取所需内容。lxml包为第三方包，需要自行安装。如果对xpath的语法还不太熟悉，可参考下面的教程：<br><a href="http://www.w3school.com.cn/xpath/xpath_syntax.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/xpath/xpath_syntax.asp</a></p><p><strong>xpath常用的规则</strong></p><table><thead><tr><th style="text-align:center">表达式</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">nodename</td><td style="text-align:center">选取此节点的所有子节点</td></tr><tr><td style="text-align:center">/</td><td style="text-align:center">从当前节点选取直接子节点</td></tr><tr><td style="text-align:center">//</td><td style="text-align:center">从当前节点选取子孙节点</td></tr><tr><td style="text-align:center">.</td><td style="text-align:center">选取当前节点</td></tr><tr><td style="text-align:center">..</td><td style="text-align:center">选取当前节点的父节点</td></tr><tr><td style="text-align:center">@</td><td style="text-align:center">选取属性</td></tr></tbody></table><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"container"</span> <span class="attr">id</span>=<span class="string">"app"</span> <span class="attr">class</span>=<span class="string">"page-board/index"</span> &gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"content"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"wrapper"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"main"</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"update-time"</span>&gt;</span>2018-08-18<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"has-fresh-text"</span>&gt;</span>已更新<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"board-content"</span>&gt;</span>榜单规则：将猫眼电影库中的经典影片，按照评分和评分人数从高到低综合排序取前100名，每天上午10点更新。相关数据来源于“猫眼电影库”。<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">dl</span> <span class="attr">class</span>=<span class="string">"board-wrapper"</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"board-index board-index-1"</span>&gt;</span>1<span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/films/1203"</span> <span class="attr">title</span>=<span class="string">"霸王别姬"</span> <span class="attr">class</span>=<span class="string">"image-link"</span> <span class="attr">data-act</span>=<span class="string">"boarditem-click"</span> <span class="attr">data-val</span>=<span class="string">"&#123;movieId:1203&#125;"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">src</span>=<span class="string">"//ms0.meituan.net/mywww/image/loading_2.e3d934bf.png"</span> <span class="attr">alt</span>=<span class="string">""</span> <span class="attr">class</span>=<span class="string">"poster-default"</span> /&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">img</span> <span class="attr">data-src</span>=<span class="string">"http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c"</span> <span class="attr">alt</span>=<span class="string">"霸王别姬"</span> <span class="attr">class</span>=<span class="string">"board-img"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"board-item-main"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"board-item-content"</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"movie-item-info"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"name"</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/films/1203"</span> <span class="attr">title</span>=<span class="string">"霸王别姬"</span> <span class="attr">data-act</span>=<span class="string">"boarditem-click"</span> <span class="attr">data-val</span>=<span class="string">"&#123;movieId:1203&#125;"</span>&gt;</span>霸王别姬<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"star"</span>&gt;</span></span><br><span class="line">                主演：张国荣,张丰毅,巩俐</span><br><span class="line">        <span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"releasetime"</span>&gt;</span>上映时间：1993-01-01(中国香港)<span class="tag">&lt;/<span class="name">p</span>&gt;</span>    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"movie-item-number score-num"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">p</span> <span class="attr">class</span>=<span class="string">"score"</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"integer"</span>&gt;</span>9.<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fraction"</span>&gt;</span>6<span class="tag">&lt;/<span class="name">i</span>&gt;</span><span class="tag">&lt;/<span class="name">p</span>&gt;</span>        </span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">      <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line">                <span class="tag">&lt;/<span class="name">dd</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">dd</span>&gt;</span></span><br></pre></td></tr></table></figure><p>根据截取的部分html网页，先来提取第1个电影排名信息，有两种方法。<br><strong>第一种：</strong>直接复制。<br>右键-Copy-Copy Xpath，得到xpath路径为：<strong>//*[@id=”app”]/div/div/div[1]/dl/dd[1]/i</strong>,为了能够提取到页面所有的排名信息，需进一步修改为：<strong>//*[@id=”app”]/div/div/div[1]/dl/dd/i/text()</strong>，如果想要再精简一点，可以省去中间部分绝对路径’/‘然后用相对路径’//‘代替，最后进一步修改为：<strong>//*[@id=”app”]//div//dd/i/text()</strong>。<br><img src="http://media.makcyun.top/18-8-19/840042.jpg" alt=""></p><p><strong>第二种：</strong>观察网页结构自己写。<br>首先注意到<strong>id = app</strong>的div节点，因为在整个网页结构id是唯一的不会有第二个相同的，所有可以将该div节点作为xpath语法的起点，然后往下观察分别是3级div节点，可以省略写为：<strong>//div</strong>,再往下分别是是两个并列的<strong>p</strong>节点、<strong>dl</strong>节点、<strong>dd</strong>节点和最后的<strong>i</strong>节点文本。中间可以随意省略，只要保证该路径能够选择到唯一的文本值<strong>‘1’</strong>即可，例如省去p和dl节点，只保留后面的节点。这样，完整路径可以为：<strong>//*[@id=”app”]//div//dd/i/text()</strong>，和上式一样。</p><p><img src="http://media.makcyun.top/18-8-19/87341266.jpg" alt=""></p><p>根据上述思路，可以写下其他内容的xpath路径。观察到路径的前一部分：<strong>//*[@id=”app”]//div//dd</strong>都是一样的，从后面才开始不同，因此为了能够精简代码，将前部分路径赋值为一个变量items，最终提取的代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 2 用lxml结合xpath提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page2</span><span class="params">(html)</span>:</span></span><br><span class="line">    parse = etree.HTML(html)</span><br><span class="line">    items = parse.xpath(<span class="string">'//*[@id="app"]//div//dd'</span>)</span><br><span class="line">    <span class="comment"># 完整的是//*[@id="app"]/div/div/div[1]/dl/dd</span></span><br><span class="line">    <span class="comment"># print(type(items))</span></span><br><span class="line">    <span class="comment"># *代表匹配所有节点，@表示属性</span></span><br><span class="line">    <span class="comment"># 第一个电影是dd[1],要提取页面所有电影则去掉[1]</span></span><br><span class="line">    <span class="comment"># xpath://*[@id="app"]/div/div/div[1]/dl/dd[1]    </span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line">            <span class="string">'index'</span>: item.xpath(<span class="string">'./i/text()'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="comment">#./i/text()前面的点表示从items节点开始</span></span><br><span class="line">            <span class="comment">#/text()提取文本</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(str(item.xpath(<span class="string">'./a/img[2]/@data-src'</span>)[<span class="number">0</span>].strip())),</span><br><span class="line">            <span class="comment"># 'thumb': 要在network中定位，在elements里会写成@src而不是@data-src，从而会报list index out of range错误。</span></span><br><span class="line">            <span class="string">'name'</span>: item.xpath(<span class="string">'./a/@title'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'star'</span>: item.xpath(<span class="string">'.//p[@class = "star"]/text()'</span>)[<span class="number">0</span>].strip(),</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span> : item.xpath(<span class="string">'.//p[@class = "score"]/i[1]/text()'</span>)[<span class="number">0</span>] + \</span><br><span class="line">            item.xpath(<span class="string">'.//p[@class = "score"]/i[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><blockquote><p><strong>Tips:</strong><br><strong>[0]：</strong>xpath后面添加了[0]是因为返回的是只有1个字符串的list，添加[0]是将list提取为字符串，使其简洁；<br><strong>Network：</strong>要在最原始的Network选项卡中定位，而不是Elements中，不然提取不到相关内容；<br><strong>class属性：</strong>p[@class = “star”]/text()表示提取class属性为”star”的p节点的文本值；<br><strong>提取属性值：</strong>img[2]/@data-src’：提取img节点的data-src属性值，属性值后面无需添加’/text()’</p></blockquote><p>运行程序，就可成功地提取出所需内容，结果和第一种方法一样。</p><p>以上是第2种提取方法，如果也不太习惯xpath语法，可以试试下面的第3种方法。</p><h4 id="3-3-3-Beautiful-Soup-css选择器"><a href="#3-3-3-Beautiful-Soup-css选择器" class="headerlink" title="3.3.3. Beautiful Soup + css选择器"></a>3.3.3. Beautiful Soup + css选择器</h4><p>Beautiful Soup 同lxml一样，是一个非常强大的python解析库，可以从HTML或XML文件中提取效率非常高。关于它的用法，可参考下面的教程：<br><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/" target="_blank" rel="noopener">https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/</a></p><p>css选择器选是一种模式，用于选择需要添加样式的元素，使用它的语法同样能够快速定位到所需节点，然后提取相应内容。使用方法可参考下面的教程：<br><a href="http://www.w3school.com.cn/cssref/css_selectors.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/cssref/css_selectors.asp</a></p><p><strong>css选择器常用的规则</strong></p><style>table th:nth-of-type(1){width:30%}</style><table><thead><tr><th style="text-align:center">选择器</th><th style="text-align:center">例子</th><th style="text-align:center">例子描述</th></tr></thead><tbody><tr><td style="text-align:center">.class</td><td style="text-align:center">.intro</td><td style="text-align:center">选择 class=”intro” 的所有元素。</td></tr><tr><td style="text-align:center">#id</td><td style="text-align:center">#firstname</td><td style="text-align:center">选择 id=”firstname” 的所有元素。</td></tr><tr><td style="text-align:center">*</td><td style="text-align:center">*</td><td style="text-align:center">选择所有元素。</td></tr><tr><td style="text-align:center">element</td><td style="text-align:center">p</td><td style="text-align:center">选择所有p元素。</td></tr><tr><td style="text-align:center">element,element</td><td style="text-align:center">div,p</td><td style="text-align:center">选择所有div元素和所有p元素。</td></tr><tr><td style="text-align:center">element?element</td><td style="text-align:center">div p</td><td style="text-align:center">选择div元素内部的所有p元素。</td></tr><tr><td style="text-align:center">element&gt;element</td><td style="text-align:center">div&gt;p</td><td style="text-align:center">选择父元素为div元素的所有p元素。</td></tr><tr><td style="text-align:center">element+element</td><td style="text-align:center">div+p</td><td style="text-align:center">选择紧接在div元素之后的所有p元素。</td></tr><tr><td style="text-align:center">[attribute]</td><td style="text-align:center">[target]</td><td style="text-align:center">选择带有 target 属性所有元素。</td></tr><tr><td style="text-align:center">[attribute=value]</td><td style="text-align:center">[target=_blank]</td><td style="text-align:center">选择 target=”_blank” 的所有元素。</td></tr></tbody></table><p>下面就利用这种方法进行提取：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 3 用beautifulsoup + css选择器提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page3</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="comment"># print(type(content))</span></span><br><span class="line">    <span class="comment"># print('------------')</span></span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.select(<span class="string">'dd i.board-index'</span>)[item].string,</span><br><span class="line">            <span class="comment"># iclass节点完整地为'board-index board-index-1',写board-index即可</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(soup.select(<span class="string">'a &gt; img.board-img'</span>)[item][<span class="string">"data-src"</span>]),</span><br><span class="line">            <span class="comment"># 表示a节点下面的class = board-img的img节点,注意浏览器eelement里面是src节点，而network里面是data-src节点，要用这个才能正确返回值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">'name'</span>: soup.select(<span class="string">'.name a'</span>)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.select(<span class="string">'.star'</span>)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: soup.select(<span class="string">'.integer'</span>)[item].string + soup.select(<span class="string">'.fraction'</span>)[item].string</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p></p><p>运行上述程序，结果同第1种方法一样。</p><h4 id="3-3-4-Beautiful-Soup-find-all函数提取"><a href="#3-3-4-Beautiful-Soup-find-all函数提取" class="headerlink" title="3.3.4. Beautiful Soup + find_all函数提取"></a>3.3.4. Beautiful Soup + find_all函数提取</h4><p>Beautifulsoup除了和css选择器搭配，还可以直接用它自带的find_all函数进行提取。<br><strong>find_all</strong>，顾名思义，就是查询所有符合条件的元素，可以给它传入一些属性或文本来得到符合条件的元素，功能十分强大。<br>它的API如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find_all(name , attrs , recursive , text , **kwargs)</span><br></pre></td></tr></table></figure><blockquote><p><strong>常用的语法规则如下：</strong><br>soup.find_all(name=’ul’)： 查找所有<strong>ul</strong>节点，ul节点内还可以嵌套；<br>li.string和li.get_text()：都是获取<strong>li</strong>节点的文本，但推荐使用后者；<br>soup.find_all(attrs={‘id’: ‘list-1’}))：传入 attrs 参数，参数的类型是字典类型，表示查询 <strong>id</strong> 为 <strong>list-1</strong> 的节点；<br>常用的属性比如 id、class 等，可以省略attrs采用更简洁的形式，例如：<br>soup.find_all(id=’list-1’)<br>soup.find_all(class_=’element’)</p></blockquote><p>根据上述常用语法，可以提取网页中所需内容：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page4</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.find_all(class_=<span class="string">'board-index'</span>)[item].string,</span><br><span class="line">            <span class="string">'thumb'</span>: soup.find_all(class_ = <span class="string">'board-img'</span>)[item].attrs[<span class="string">'data-src'</span>],</span><br><span class="line">            <span class="comment"># 用.get('data-src')获取图片src链接，或者用attrs['data-src']</span></span><br><span class="line">            <span class="string">'name'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span> : <span class="string">'name'</span>&#125;)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'star'</span>&#125;)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>:soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'integer'</span>&#125;)[item].string.strip() + soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'fraction'</span>&#125;)[item].string.strip()</span><br><span class="line"></span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>以上就是4种不同的内容提取方法。</p><h3 id="3-4-数据存储"><a href="#3-4-数据存储" class="headerlink" title="3.4. 数据存储"></a>3.4. 数据存储</h3><p>上述输出的结果为字典格式，可利用csv包的DictWriter函数将字典格式数据存储到csv文件中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据存储到csv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file3</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'猫眼top100.csv'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf_8_sig'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 'a'为追加模式（添加）</span></span><br><span class="line">        <span class="comment"># utf_8_sig格式导出csv不乱码 </span></span><br><span class="line">        fieldnames = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]</span><br><span class="line">        w = csv.DictWriter(f,fieldnames = fieldnames)</span><br><span class="line">        <span class="comment"># w.writeheader()</span></span><br><span class="line">        w.writerow(item)</span><br></pre></td></tr></table></figure><p>然后修改一下main()方法：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        write_to_csv(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p></p><p>结果如下图：<br><img src="http://media.makcyun.top/18-8-20/66910595.jpg" alt=""></p><p>再将封面的图片下载下来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_thumb</span><span class="params">(name, url,num)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'封面图/'</span> + name + <span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line">            print(<span class="string">'第%s部电影封面下载完毕'</span> %num)</span><br><span class="line">            print(<span class="string">'------'</span>)</span><br><span class="line">    <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     <span class="comment"># 不能是w，否则会报错，因为图片是二进制数据所以要用wb</span></span><br></pre></td></tr></table></figure><h3 id="3-5-分页爬取"><a href="#3-5-分页爬取" class="headerlink" title="3.5. 分页爬取"></a>3.5. 分页爬取</h3><p>上面完成了一页电影数据的提取，接下来还需提取剩下9页共90部电影的数据。对网址进行遍历，给网址传入一个offset参数即可，修改如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  </span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        write_to_csv(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        main(offset = i*<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>这样就完成了所有电影的爬取。结果如下：</p><p><img src="http://media.makcyun.top/18-8-19/28479553.jpg" alt=""></p><p><img src="http://media.makcyun.top/18-8-19/34117279.jpg" alt=""></p><h2 id="4-可视化分析"><a href="#4-可视化分析" class="headerlink" title="4. 可视化分析"></a>4. 可视化分析</h2><p>俗话说“文不如表，表不如图”。下面根据excel的数据结果，进行简单的数据可视化分析，并用图表呈现。</p><h3 id="4-1-电影评分最高top10"><a href="#4-1-电影评分最高top10" class="headerlink" title="4.1. 电影评分最高top10"></a>4.1. 电影评分最高top10</h3><p>首先，想看一看评分最高的前10部电影是哪些？</p><p>程序如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl  <span class="comment">#用于修改x轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)   <span class="comment">#默认绘图风格很难看，替换为好看的ggplot风格</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>,<span class="number">5</span>))   <span class="comment">#设置图片大小</span></span><br><span class="line">colors1 = <span class="string">'#6D6D6D'</span>  <span class="comment">#设置图表title、text标注的颜色</span></span><br><span class="line"></span><br><span class="line">columns = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]  <span class="comment">#设置表头</span></span><br><span class="line">df = pd.read_csv(<span class="string">'maoyan_top100.csv'</span>,encoding = <span class="string">"utf-8"</span>,header = <span class="keyword">None</span>,names =columns,index_col = <span class="string">'index'</span>)  <span class="comment">#打开表格</span></span><br><span class="line"><span class="comment"># index_col = 'index' 将索引设为index</span></span><br><span class="line"></span><br><span class="line">df_score = df.sort_values(<span class="string">'score'</span>,ascending = <span class="keyword">False</span>)  <span class="comment">#按得分降序排列</span></span><br><span class="line"></span><br><span class="line">name1 = df_score.name[:<span class="number">10</span>]      <span class="comment">#x轴坐标</span></span><br><span class="line">score1 = df_score.score[:<span class="number">10</span>]    <span class="comment">#y轴坐标  </span></span><br><span class="line">plt.bar(range(<span class="number">10</span>),score1,tick_label = name1)  <span class="comment">#绘制条形图，用range()能搞保持x轴正确顺序</span></span><br><span class="line">plt.ylim ((<span class="number">9</span>,<span class="number">9.8</span>))  <span class="comment">#设置纵坐标轴范围</span></span><br><span class="line">plt.title(<span class="string">'电影评分最高top10'</span>,color = colors1) <span class="comment">#标题</span></span><br><span class="line">plt.xlabel(<span class="string">'电影名称'</span>)      <span class="comment">#x轴标题</span></span><br><span class="line">plt.ylabel(<span class="string">'评分'</span>)          <span class="comment">#y轴标题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个条形图添加数值标签</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(score1)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.01</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line"></span><br><span class="line">pl.xticks(rotation=<span class="number">270</span>)   <span class="comment">#x轴名称太长发生重叠，旋转为纵向显示</span></span><br><span class="line">plt.tight_layout()    <span class="comment">#自动控制空白边缘，以全部显示x轴名称</span></span><br><span class="line"><span class="comment"># plt.savefig('电影评分最高top10.png')   #保存图片</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><p>结果如下图：<br><img src="http://media.makcyun.top/18-8-20/80083042.jpg" alt=""><br>可以看到：排名最高的分别是两部国产片”霸王别姬”和”大话西游”，其他还包括”肖申克的救赎”、”教父”等。<br>嗯，还好基本上都看过。</p><h3 id="4-2-各国家的电影数量比较"><a href="#4-2-各国家的电影数量比较" class="headerlink" title="4.2. 各国家的电影数量比较"></a>4.2. 各国家的电影数量比较</h3><p>然后，想看看100部电影都是来自哪些国家？<br>程序如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">area_count = df.groupby(by = <span class="string">'area'</span>).area.count().sort_values(ascending = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图方法1</span></span><br><span class="line">area_count.plot.bar(color = <span class="string">'#4652B1'</span>)  <span class="comment">#设置为蓝紫色</span></span><br><span class="line">pl.xticks(rotation=<span class="number">0</span>)   <span class="comment">#x轴名称太长重叠，旋转为纵向</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图方法2</span></span><br><span class="line"><span class="comment"># plt.bar(range(11),area_count.values,tick_label = area_count.index)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(area_count.values)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.5</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line">plt.title(<span class="string">'各国/地区电影数量排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'国家/地区'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('各国(地区)电影数量排名.png')</span></span><br></pre></td></tr></table></figure><p></p><p>结果如下图：<br><img src="http://media.makcyun.top/18-8-21/57684234.jpg" alt=""><br>可以看到，除去网站自身没有显示国家的电影以外，上榜电影被10个国家/地区”承包”了。其中，美国以30部电影的绝对优势占据第1名，其次是8部的日本，韩国第3，居然有7部上榜。<br>不得不说的是香港有5部，而内地一部都没有。。。</p><h3 id="4-3-电影作品数量集中的年份"><a href="#4-3-电影作品数量集中的年份" class="headerlink" title="4.3. 电影作品数量集中的年份"></a>4.3. 电影作品数量集中的年份</h3><p>接下来站在漫长的百年电影史的时间角度上，分析一下哪些年份”贡献了”最多的电影数量，也可以说是”电影大年”。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从日期中提取年份</span></span><br><span class="line">df[<span class="string">'year'</span>] = df[<span class="string">'time'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">'/'</span>)[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># print(df.info())</span></span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计各年上映的电影数量</span></span><br><span class="line">grouped_year = df.groupby(<span class="string">'year'</span>)</span><br><span class="line">grouped_year_amount = grouped_year.year.count()</span><br><span class="line">top_year = grouped_year_amount.sort_values(ascending = <span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">top_year.plot(kind = <span class="string">'bar'</span>,color = <span class="string">'orangered'</span>) <span class="comment">#颜色设置为橙红色</span></span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(list(top_year.values)):</span><br><span class="line">    plt.text(x,y+<span class="number">0.1</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line">plt.title(<span class="string">'电影数量年份排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'年份(年)'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.savefig('电影数量年份排名.png')</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><p>结果如下图：<br><img src="http://media.makcyun.top/18-8-20/32342735.jpg" alt=""></p><p>可以看到，100部电影来自37个年份。其中2011年上榜电影数量最多，达到9部；其次是前一年的7部。回忆一下，那会儿正是上大学的头两年，可怎么感觉除了阿凡达之外，没有什么其他有印象的电影了。。。<br>另外，网上传的号称”电影史奇迹年”的1994年仅排名第6。这让我进一步对猫眼榜单的权威性产生了质疑。<br>再往后看，发现遥远的1939和1940年也有电影上榜。那会儿应该还是黑白电影时代吧，看来电影的口碑好坏跟外在的技术没有绝对的关系，质量才是王道。</p><h3 id="4-4-拥有电影作品数量最多的演员"><a href="#4-4-拥有电影作品数量最多的演员" class="headerlink" title="4.4 拥有电影作品数量最多的演员"></a>4.4 拥有电影作品数量最多的演员</h3><p>最后，看看前100部电影中哪些演员的作品数量最多。<br>程序如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#表中的演员位于同一列，用逗号分割符隔开。需进行分割然后全部提取到list中</span></span><br><span class="line">starlist = []</span><br><span class="line">star_total = df.star</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> df.star.str.replace(<span class="string">' '</span>,<span class="string">''</span>).str.split(<span class="string">','</span>):</span><br><span class="line">    starlist.extend(i)  </span><br><span class="line"><span class="comment"># print(starlist)</span></span><br><span class="line"><span class="comment"># print(len(starlist))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set去除重复的演员名</span></span><br><span class="line">starall = set(starlist)</span><br><span class="line"><span class="comment"># print(starall)</span></span><br><span class="line"><span class="comment"># print(len(starall))</span></span><br><span class="line"></span><br><span class="line">starall2 = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> starall:</span><br><span class="line">    <span class="keyword">if</span> starlist.count(i)&gt;<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 筛选出电影数量超过1部的演员</span></span><br><span class="line">        starall2[i] = starlist.count(i)</span><br><span class="line"></span><br><span class="line">starall2 = sorted(starall2.items(),key = <span class="keyword">lambda</span> starlist:starlist[<span class="number">1</span>] ,reverse = <span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">starall2 = dict(starall2[:<span class="number">10</span>])  <span class="comment">#将元组转为字典格式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">x_star = list(starall2.keys())      <span class="comment">#x轴坐标</span></span><br><span class="line">y_star = list(starall2.values())    <span class="comment">#y轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.bar(range(<span class="number">10</span>),y_star,tick_label = x_star)</span><br><span class="line">pl.xticks(rotation = <span class="number">270</span>)</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> enumerate(y_star):</span><br><span class="line">    plt.text(x,y+<span class="number">0.1</span>,<span class="string">'%s'</span> %round(y,<span class="number">1</span>),ha = <span class="string">'center'</span>,color = colors1)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">'演员电影作品数量排名'</span>,color = colors1)</span><br><span class="line">plt.xlabel(<span class="string">'演员'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()    </span><br><span class="line"><span class="comment"># plt.savefig('演员电影作品数量排名.png')</span></span><br></pre></td></tr></table></figure><p></p><p>结果如下图：<br><img src="http://media.makcyun.top/18-8-20/66062822.jpg" alt=""></p><p>张国荣排在了第一位，这是之前没有猜到的。其次是梁朝伟和星爷，再之后是布拉德·皮特。惊奇地发现，前十名影星中，香港影星居然占了6位。有点严重怀疑这是不是香港版的top100电影。。。</p><p>对张国荣以7部影片的巨大优势雄霸榜单第一位感到好奇，想看看是哪7部电影。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'star1'</span>] = df[<span class="string">'star'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">','</span>)[<span class="number">0</span>])  <span class="comment">#提取1号演员</span></span><br><span class="line">df[<span class="string">'star2'</span>] = df[<span class="string">'star'</span>].map(<span class="keyword">lambda</span> x:x.split(<span class="string">','</span>)[<span class="number">1</span>])  <span class="comment">#提取2号演员</span></span><br><span class="line">star_most = df[(df.star1 == <span class="string">'张国荣'</span>) | (df.star2 == <span class="string">'张国荣'</span>)][[<span class="string">'star'</span>,<span class="string">'name'</span>]].reset_index(<span class="string">'index'</span>)</span><br><span class="line"><span class="comment"># |表示两个条件或查询，之后重置索引</span></span><br><span class="line">print(star_most)</span><br></pre></td></tr></table></figure><p></p><p>可以看到包括排名第1的”霸王别姬”、第17名的”春光乍泄”、第27名的”射雕英雄传之东成西就”等。<br>突然发现，好像只看过”英雄本色”。。。有时间，去看看他其他的作品。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">     index        star              name</span><br><span class="line">0      1   张国荣,张丰毅,巩俐        霸王别姬</span><br><span class="line">1     17   张国荣,梁朝伟,张震        春光乍泄</span><br><span class="line">2     27  张国荣,梁朝伟,张学友  射雕英雄传之东成西就</span><br><span class="line">3     37  张国荣,梁朝伟,刘嘉玲        东邪西毒</span><br><span class="line">4     70   张国荣,王祖贤,午马        倩女幽魂</span><br><span class="line">5     99  张国荣,张曼玉,刘德华        阿飞正传</span><br><span class="line">6    100   狄龙,张国荣,周润发        英雄本色</span><br></pre></td></tr></table></figure><p>由于数据量有限，故仅作了上述简要的分析。</p><h2 id="5-完整程序"><a href="#5-完整程序" class="headerlink" title="5. 完整程序"></a>5. 完整程序</h2><p>最后，将前面爬虫的所有代码整理一下，完整的代码如下：<br>一、爬虫部分<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_one_page</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        headers = &#123;</span><br><span class="line">            <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36'</span>&#125;</span><br><span class="line">        <span class="comment"># 不加headers爬不了</span></span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 用正则提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page</span><span class="params">(html)</span>:</span></span><br><span class="line">    pattern = re.compile(</span><br><span class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</span><br><span class="line">    <span class="comment"># re.S表示匹配任意字符，如果不加.无法匹配换行符</span></span><br><span class="line">    items = re.findall(pattern, html)</span><br><span class="line">    <span class="comment"># print(items)</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'index'</span>: item[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(item[<span class="number">1</span>]),</span><br><span class="line">            <span class="string">'name'</span>: item[<span class="number">2</span>],</span><br><span class="line">            <span class="string">'star'</span>: item[<span class="number">3</span>].strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="comment"># 'time': item[4].strip()[5:],</span></span><br><span class="line">            <span class="comment"># 用函数分别提取time里的日期和地区</span></span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item[<span class="number">4</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: item[<span class="number">5</span>].strip() + item[<span class="number">6</span>].strip()</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line"><span class="comment"># 2 用lxml结合xpath提取内容</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page2</span><span class="params">(html)</span>:</span></span><br><span class="line">    parse = etree.HTML(html)</span><br><span class="line">    items = parse.xpath(<span class="string">'//*[@id="app"]//div//dd'</span>)</span><br><span class="line">    <span class="comment"># 完整的是//*[@id="app"]/div/div/div[1]/dl/dd</span></span><br><span class="line">    <span class="comment"># print(type(items))</span></span><br><span class="line">    <span class="comment"># *代表匹配所有节点，@表示属性</span></span><br><span class="line">    <span class="comment"># 第一个电影是dd[1],要提取页面所有电影则去掉[1]</span></span><br><span class="line">    <span class="comment"># xpath://*[@id="app"]/div/div/div[1]/dl/dd[1]</span></span><br><span class="line">    <span class="comment"># lst = []</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line">            <span class="string">'index'</span>: item.xpath(<span class="string">'./i/text()'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="comment">#./i/text()前面的点表示从items节点开始</span></span><br><span class="line">            <span class="comment">#/text()提取文本</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(str(item.xpath(<span class="string">'./a/img[2]/@data-src'</span>)[<span class="number">0</span>].strip())),</span><br><span class="line">            <span class="comment"># 'thumb': 要在network中定位，在elements里会写成@src而不是@data-src，从而会报list index out of range错误。</span></span><br><span class="line">            <span class="string">'name'</span>: item.xpath(<span class="string">'./a/@title'</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">'star'</span>: item.xpath(<span class="string">'.//p[@class = "star"]/text()'</span>)[<span class="number">0</span>].strip(),</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(item.xpath(</span><br><span class="line">                <span class="string">'.//p[@class = "releasetime"]/text()'</span>)[<span class="number">0</span>].strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span> : item.xpath(<span class="string">'.//p[@class = "score"]/i[1]/text()'</span>)[<span class="number">0</span>] + \</span><br><span class="line">            item.xpath(<span class="string">'.//p[@class = "score"]/i[2]/text()'</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"><span class="comment"># 3 用beautifulsoup + css选择器提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page3</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="comment"># print(content)</span></span><br><span class="line">    <span class="comment"># print(type(content))</span></span><br><span class="line">    <span class="comment"># print('------------')</span></span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.select(<span class="string">'dd i.board-index'</span>)[item].string,</span><br><span class="line">            <span class="comment"># iclass节点完整地为'board-index board-index-1',写board-inde即可</span></span><br><span class="line">            <span class="string">'thumb'</span>: get_thumb(soup.select(<span class="string">'a &gt; img.board-img'</span>)[item][<span class="string">"data-src"</span>]),</span><br><span class="line">            <span class="comment"># 表示a节点下面的class = board-img的img节点,注意浏览器eelement里面是src节点，而network里面是data-src节点，要用这个才能正确返回值</span></span><br><span class="line"></span><br><span class="line">            <span class="string">'name'</span>: soup.select(<span class="string">'.name a'</span>)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.select(<span class="string">'.star'</span>)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_area(soup.select(<span class="string">'.releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>: soup.select(<span class="string">'.integer'</span>)[item].string + soup.select(<span class="string">'.fraction'</span>)[item].string</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4 用beautifulsoup + find_all提取</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_one_page4</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html,<span class="string">'lxml'</span>)</span><br><span class="line">    items = range(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        <span class="keyword">yield</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="string">'index'</span>: soup.find_all(class_=<span class="string">'board-index'</span>)[item].string,</span><br><span class="line">            <span class="string">'thumb'</span>: soup.find_all(class_ = <span class="string">'board-img'</span>)[item].attrs[<span class="string">'data-src'</span>],</span><br><span class="line">            <span class="comment"># 用.get('data-src')获取图片src链接，或者用attrs['data-src']</span></span><br><span class="line">            <span class="string">'name'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span> : <span class="string">'name'</span>&#125;)[item].string,</span><br><span class="line">            <span class="string">'star'</span>: soup.find_all(name = <span class="string">'p'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'star'</span>&#125;)[item].string.strip()[<span class="number">3</span>:],</span><br><span class="line">            <span class="string">'time'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'area'</span>: get_release_time(soup.find_all(class_ =<span class="string">'releasetime'</span>)[item].string.strip()[<span class="number">5</span>:]),</span><br><span class="line">            <span class="string">'score'</span>:soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'integer'</span>&#125;)[item].string.strip() + soup.find_all(name = <span class="string">'i'</span>,attrs = &#123;<span class="string">'class'</span>:<span class="string">'fraction'</span>&#125;)[item].string.strip()</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取时间函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_time</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)(\(|$)'</span>)</span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)  <span class="comment"># 返回匹配到的第一个括号(.*?)中结果即时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取国家/地区函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_release_area</span><span class="params">(data)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'.*\((.*)\)'</span>)</span><br><span class="line">    <span class="comment"># $表示匹配一行字符串的结尾，这里就是(.*?)；\(|$,表示匹配字符串含有(,或者只有(.*?)</span></span><br><span class="line">    items = re.search(pattern, data)</span><br><span class="line">    <span class="keyword">if</span> items <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'未知'</span></span><br><span class="line">    <span class="keyword">return</span> items.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取封面大图</span></span><br><span class="line"><span class="comment"># http://p0.meituan.net/movie/5420be40e3b755ffe04779b9b199e935256906.jpg@160w_220h_1e_1c</span></span><br><span class="line"><span class="comment"># 去掉@160w_220h_1e_1c就是大图</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_thumb</span><span class="params">(url)</span>:</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'(.*?)@.*?'</span>)</span><br><span class="line">    thumb = re.search(pattern, url)</span><br><span class="line">    <span class="keyword">return</span> thumb.group(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据存储到csv</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file3</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'猫眼top100.csv'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf_8_sig'</span>,newline=<span class="string">''</span>) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="comment"># 'a'为追加模式（添加）</span></span><br><span class="line">        <span class="comment"># utf_8_sig格式导出csv不乱码 </span></span><br><span class="line">        fieldnames = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]</span><br><span class="line">        w = csv.DictWriter(f,fieldnames = fieldnames)</span><br><span class="line">        <span class="comment"># w.writeheader()</span></span><br><span class="line">        w.writerow(item)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 封面下载</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download_thumb</span><span class="params">(name, url,num)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'封面图/'</span> + name + <span class="string">'.jpg'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.content)</span><br><span class="line">            print(<span class="string">'第%s部电影封面下载完毕'</span> %num)</span><br><span class="line">            print(<span class="string">'------'</span>)</span><br><span class="line">    <span class="keyword">except</span> RequestException <span class="keyword">as</span> e:</span><br><span class="line">        print(e)</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">     <span class="comment"># 存储格式是wb,因为图片是二进制数格式，不能用w，否则会报错</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -----------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(offset)</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</span><br><span class="line">    html = get_one_page(url)</span><br><span class="line">    <span class="comment"># print(html)</span></span><br><span class="line">    <span class="comment"># parse_one_page2(html)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):  <span class="comment"># 切换内容提取方法</span></span><br><span class="line">        print(item)</span><br><span class="line">        write_to_file(item)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 下载封面图</span></span><br><span class="line">        download_thumb(item[<span class="string">'name'</span>], item[<span class="string">'thumb'</span>],item[<span class="string">'index'</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># if __name__ == '__main__':</span></span><br><span class="line"><span class="comment">#     for i in range(10):</span></span><br><span class="line"><span class="comment">#         main(i * 10)</span></span><br><span class="line">        <span class="comment"># time.sleep(0.5)</span></span><br><span class="line">        <span class="comment"># 猫眼增加了反爬虫，设置0.5s的延迟时间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 使用多进程提升抓取效率</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    pool = Pool()</span><br><span class="line">    pool.map(main, [i * <span class="number">10</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br></pre></td></tr></table></figure><p></p><p>二、可视化部分<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 可视化分析</span></span><br><span class="line"><span class="comment"># -------------------------------</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pylab <span class="keyword">as</span> pl  <span class="comment"># 用于修改x轴坐标</span></span><br><span class="line"></span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)  <span class="comment"># 默认绘图风格很难看，替换为好看的ggplot风格</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))  <span class="comment"># 设置图片大小</span></span><br><span class="line">colors1 = <span class="string">'#6D6D6D'</span>  <span class="comment"># 设置图表title、text标注的颜色</span></span><br><span class="line">columns = [<span class="string">'index'</span>, <span class="string">'thumb'</span>, <span class="string">'name'</span>, <span class="string">'star'</span>, <span class="string">'time'</span>, <span class="string">'area'</span>, <span class="string">'score'</span>]  <span class="comment"># 设置表头</span></span><br><span class="line">df = pd.read_csv(<span class="string">'maoyan_top100.csv'</span>, encoding=<span class="string">"utf-8"</span>,</span><br><span class="line">                 header=<span class="keyword">None</span>, names=columns, index_col=<span class="string">'index'</span>)  <span class="comment"># 打开表格</span></span><br><span class="line"><span class="comment"># index_col = 'index' 将索引设为index</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1电影评分最高top10</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_1</span><span class="params">()</span>:</span></span><br><span class="line">    df_score = df.sort_values(<span class="string">'score'</span>, ascending=<span class="keyword">False</span>)  <span class="comment"># 按得分降序排列</span></span><br><span class="line"></span><br><span class="line">    name1 = df_score.name[:<span class="number">10</span>]  <span class="comment"># x轴坐标</span></span><br><span class="line">    score1 = df_score.score[:<span class="number">10</span>]  <span class="comment"># y轴坐标</span></span><br><span class="line">    plt.bar(range(<span class="number">10</span>), score1, tick_label=name1)  <span class="comment"># 绘制条形图，用range()能搞保持x轴正确顺序</span></span><br><span class="line">    plt.ylim((<span class="number">9</span>, <span class="number">9.8</span>))  <span class="comment"># 设置纵坐标轴范围</span></span><br><span class="line">    plt.title(<span class="string">'电影评分最高top10'</span>, color=colors1)  <span class="comment"># 标题</span></span><br><span class="line">    plt.xlabel(<span class="string">'电影名称'</span>)  <span class="comment"># x轴标题</span></span><br><span class="line">    plt.ylabel(<span class="string">'评分'</span>)  <span class="comment"># y轴标题</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 为每个条形图添加数值标签</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(list(score1)):</span><br><span class="line">        plt.text(x, y + <span class="number">0.01</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line"></span><br><span class="line">    pl.xticks(rotation=<span class="number">270</span>)  <span class="comment"># x轴名称太长发生重叠，旋转为纵向显示</span></span><br><span class="line">    plt.tight_layout()  <span class="comment"># 自动控制空白边缘，以全部显示x轴名称</span></span><br><span class="line">    <span class="comment"># plt.savefig('电影评分最高top10.png')   #保存图片</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># 2各国家的电影数量比较</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_2</span><span class="params">()</span>:</span></span><br><span class="line">    area_count = df.groupby(</span><br><span class="line">        by=<span class="string">'area'</span>).area.count().sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图方法1</span></span><br><span class="line">    area_count.plot.bar(color=<span class="string">'#4652B1'</span>)  <span class="comment"># 设置为蓝紫色</span></span><br><span class="line">    pl.xticks(rotation=<span class="number">0</span>)  <span class="comment"># x轴名称太长重叠，旋转为纵向</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图方法2</span></span><br><span class="line">    <span class="comment"># plt.bar(range(11),area_count.values,tick_label = area_count.index,color</span></span><br><span class="line">    <span class="comment"># = '#4652B1')</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(list(area_count.values)):</span><br><span class="line">        plt.text(x, y + <span class="number">0.5</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line">    plt.title(<span class="string">'各国/地区电影数量排名'</span>, color=colors1)</span><br><span class="line">    plt.xlabel(<span class="string">'国家/地区'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('各国(地区)电影数量排名.png')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># 3电影作品数量集中的年份</span></span><br><span class="line"><span class="comment"># 从日期中提取年份</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_3</span><span class="params">()</span>:</span></span><br><span class="line">    df[<span class="string">'year'</span>] = df[<span class="string">'time'</span>].map(<span class="keyword">lambda</span> x: x.split(<span class="string">'/'</span>)[<span class="number">0</span>])</span><br><span class="line">    <span class="comment"># print(df.info())</span></span><br><span class="line">    <span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计各年上映的电影数量</span></span><br><span class="line">    grouped_year = df.groupby(<span class="string">'year'</span>)</span><br><span class="line">    grouped_year_amount = grouped_year.year.count()</span><br><span class="line">    top_year = grouped_year_amount.sort_values(ascending=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    top_year.plot(kind=<span class="string">'bar'</span>, color=<span class="string">'orangered'</span>)  <span class="comment"># 颜色设置为橙红色</span></span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(list(top_year.values)):</span><br><span class="line">        plt.text(x, y + <span class="number">0.1</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line">    plt.title(<span class="string">'电影数量年份排名'</span>, color=colors1)</span><br><span class="line">    plt.xlabel(<span class="string">'年份(年)'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line"></span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    <span class="comment"># plt.savefig('电影数量年份排名.png')</span></span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------------------------------</span></span><br><span class="line"><span class="comment"># 4拥有电影作品数量最多的演员</span></span><br><span class="line"><span class="comment"># 表中的演员位于同一列，用逗号分割符隔开。需进行分割然后全部提取到list中</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">annalysis_4</span><span class="params">()</span>:</span></span><br><span class="line">    starlist = []</span><br><span class="line">    star_total = df.star</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> df.star.str.replace(<span class="string">' '</span>, <span class="string">''</span>).str.split(<span class="string">','</span>):</span><br><span class="line">        starlist.extend(i)</span><br><span class="line">    <span class="comment"># print(starlist)</span></span><br><span class="line">    <span class="comment"># print(len(starlist))</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># set去除重复的演员名</span></span><br><span class="line">    starall = set(starlist)</span><br><span class="line">    <span class="comment"># print(starall)</span></span><br><span class="line">    <span class="comment"># print(len(starall))</span></span><br><span class="line"></span><br><span class="line">    starall2 = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> starall:</span><br><span class="line">        <span class="keyword">if</span> starlist.count(i) &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="comment"># 筛选出电影数量超过1部的演员</span></span><br><span class="line">            starall2[i] = starlist.count(i)</span><br><span class="line"></span><br><span class="line">    starall2 = sorted(starall2.items(),</span><br><span class="line">                      key=<span class="keyword">lambda</span> starlist: starlist[<span class="number">1</span>], reverse=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">    starall2 = dict(starall2[:<span class="number">10</span>])  <span class="comment"># 将元组转为字典格式</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 绘图</span></span><br><span class="line">    x_star = list(starall2.keys())  <span class="comment"># x轴坐标</span></span><br><span class="line">    y_star = list(starall2.values())  <span class="comment"># y轴坐标</span></span><br><span class="line"></span><br><span class="line">    plt.bar(range(<span class="number">10</span>), y_star, tick_label=x_star)</span><br><span class="line">    pl.xticks(rotation=<span class="number">270</span>)</span><br><span class="line">    <span class="keyword">for</span> x, y <span class="keyword">in</span> enumerate(y_star):</span><br><span class="line">        plt.text(x, y + <span class="number">0.1</span>, <span class="string">'%s'</span> % round(y, <span class="number">1</span>), ha=<span class="string">'center'</span>, color=colors1)</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">'演员电影作品数量排名'</span>, color=colors1)</span><br><span class="line">    plt.xlabel(<span class="string">'演员'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'数量(部)'</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="comment"># plt.savefig('演员电影作品数量排名.png')</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    annalysis_1()</span><br><span class="line">    annalysis_2()</span><br><span class="line">    annalysis_3()</span><br><span class="line">    annalysis_4()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p></p></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>你一打赏，我就写得更来劲了</div><button id="rewardButton" disable="enable" onclick='var e=document.getElementById("QR");"none"===e.style.display?e.style.display="block":e.style.display="none"'><span>打赏</span></button><div id="QR" style="display:none"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/wechatpay.png" alt="高级农民工 微信支付"><p>微信支付</p></div></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/requests/" rel="tag"><i class="fa fa-tag"></i> requests</a> <a href="/tags/正则表达式/" rel="tag"><i class="fa fa-tag"></i> 正则表达式</a> <a href="/tags/beautifulsoup/" rel="tag"><i class="fa fa-tag"></i> beautifulsoup</a> <a href="/tags/css/" rel="tag"><i class="fa fa-tag"></i> css</a> <a href="/tags/xpath/" rel="tag"><i class="fa fa-tag"></i> xpath</a> <a href="/tags/lxml/" rel="tag"><i class="fa fa-tag"></i> lxml</a> <a href="/tags/Python爬虫/" rel="tag"><i class="fa fa-tag"></i> Python爬虫</a></div><div class="post-widgets"><div class="wp_rating"><div style="color:rgba(0,0,0,.75);font-size:13px;letter-spacing:3px">(&gt;你觉得这篇文章怎么样？&lt;)</div><div id="wpac-rating"></div></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/08/27/web_scraping_withpython2.html" rel="prev" title="Python爬虫(2)：10行代码爬取全国所有A股/港股/新三板上市公司信息"><i class="fa fa-chevron-left"></i> Python爬虫(2)：10行代码爬取全国所有A股/港股/新三板上市公司信息</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/07/17/hexo02.html" rel="next" title="4块钱,用Github+Hexo搭建你的个人博客：美化篇">4块钱,用Github+Hexo搭建你的个人博客：美化篇 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="http://media.makcyun.top/201901230951_146.jpg" alt="高级农民工"><p class="site-author-name" itemprop="name">高级农民工</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">85</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">13</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">43</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/makcyun" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:johnny824lee@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-为什么爬取该网页？"><span class="nav-text">1. 为什么爬取该网页？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-爬虫目标"><span class="nav-text">2. 爬虫目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-爬取步骤"><span class="nav-text">3. 爬取步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-网址URL分析"><span class="nav-text">3.1. 网址URL分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Requests获取首页数据"><span class="nav-text">3.2. Requests获取首页数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-4种内容解析提取方法"><span class="nav-text">3.3. 4种内容解析提取方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-1-正则表达式提取"><span class="nav-text">3.3.1. 正则表达式提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-2-lxml结合xpath提取"><span class="nav-text">3.3.2. lxml结合xpath提取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-3-Beautiful-Soup-css选择器"><span class="nav-text">3.3.3. Beautiful Soup + css选择器</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-4-Beautiful-Soup-find-all函数提取"><span class="nav-text">3.3.4. Beautiful Soup + find_all函数提取</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-数据存储"><span class="nav-text">3.4. 数据存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-分页爬取"><span class="nav-text">3.5. 分页爬取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-可视化分析"><span class="nav-text">4. 可视化分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-电影评分最高top10"><span class="nav-text">4.1. 电影评分最高top10</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-各国家的电影数量比较"><span class="nav-text">4.2. 各国家的电影数量比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-电影作品数量集中的年份"><span class="nav-text">4.3. 电影作品数量集中的年份</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-拥有电影作品数量最多的演员"><span class="nav-text">4.4 拥有电影作品数量最多的演员</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-完整程序"><span class="nav-text">5. 完整程序</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span> <span class="with-love" id="heart"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">高级农民工</span></div><script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_uv">访客数：<span id="busuanzi_value_site_uv"></span>人次</span> <span class="post-meta-divider">|</span> <span id="busuanzi_container_site_pv">总访问量：<span id="busuanzi_value_site_pv"></span>次</span> <span class="post-meta-divider">|</span><div class="theme-info"><div class="powered-by"></div><span class="post-count">全站共：193.5k字</span></div><div style="width:300px;margin:0 auto;padding:10px 0"><a target="_blank" style="display:inline-block;text-decoration:none;height:20px;line-height:20px"><img src="" style="float:left"><p style="float:left;height:20px;line-height:20px;margin:0 0 0 5px;color:#939393">粤ICP备18144842号</p></a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(t,e,o){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var n=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,r=document.getElementById(e),s=document.getElementById(o),a=function(){var t=r.value.trim().toLowerCase(),e=t.split(/[\s\-]+/);e.length>1&&e.push(t);var o=[];if(t.length>0&&n.forEach(function(n){function r(e,o,n,r){for(var s=r[r.length-1],a=s.position,i=s.word,l=[],h=0;a+i.length<=n&&0!=r.length;){i===t&&h++,l.push({position:a,length:i.length});var p=a+i.length;for(r.pop();0!=r.length&&(s=r[r.length-1],a=s.position,i=s.word,p>a);)r.pop()}return c+=h,{hits:l,start:o,end:n,searchTextCount:h}}function s(t,e){var o="",n=e.start;return e.hits.forEach(function(e){o+=t.substring(n,e.position);var r=e.position+e.length;o+='<b class="search-keyword">'+t.substring(e.position,r)+"</b>",n=r}),o+=t.substring(n,e.end)}var a=!1,i=0,c=0,l=n.title.trim(),h=l.toLowerCase(),p=n.content.trim().replace(/<[^>]+>/g,""),u=p.toLowerCase(),f=decodeURIComponent(n.url),d=[],g=[];if(""!=l&&(e.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());(s=e.indexOf(t,r))>-1;)a.push({position:s,word:t}),r=s+n;return a}d=d.concat(e(t,h,!1)),g=g.concat(e(t,u,!1))}),(d.length>0||g.length>0)&&(a=!0,i=d.length+g.length)),a){[d,g].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});var v=[];0!=d.length&&v.push(r(l,0,l.length,d));for(var $=[];0!=g.length;){var C=g[g.length-1],m=C.position,x=C.word,w=m-20,y=m+80;0>w&&(w=0),y<m+x.length&&(y=m+x.length),y>p.length&&(y=p.length),$.push(r(p,w,y,g))}$.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var T=parseInt("1");T>=0&&($=$.slice(0,T));var b="";b+=0!=v.length?"<li><a href='"+f+"' class='search-result-title'>"+s(l,v[0])+"</a>":"<li><a href='"+f+"' class='search-result-title'>"+l+"</a>",$.forEach(function(t){b+="<a href='"+f+'\'><p class="search-result">'+s(p,t)+"...</p></a>"}),b+="</li>",o.push({item:b,searchTextCount:c,hitCount:i,id:o.length})}}),1===e.length&&""===e[0])s.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===o.length)s.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{o.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var a='<ul class="search-result-list">';o.forEach(function(t){a+=t.item}),a+="</ul>",s.innerHTML=a}};r.addEventListener("input",a),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),isfetched===!1?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){var e=27===t.which&&$(".search-popup").is(":visible");e&&onPopupClose()})</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("yps9pUuWWGeNG1MwVI2tVGys-gzGzoHsz","SNn7AhhHPrCndytXWSTwD5A2")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script><script type="text/javascript">wpac_init=window.wpac_init||[],wpac_init.push({widget:"Rating",id:12522,el:"wpac-rating",color:"E0943E"}),function(){if(!("WIDGETPACK_LOADED"in window)){WIDGETPACK_LOADED=!0;var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//embed.widgetpack.com/widget.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t.nextSibling)}}()</script></body></html><!-- rebuild by neat -->